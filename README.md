# Urban-sound-recognition-system
<h2>Introduction</h2>
<ul>
<li>Sounds make up a lot of physical events in the city, therefore, developing deep learning approach to automatically extract this information has a huge potential and application in areas like building smart-city: noise monitoring, urban security, soundscape assessment, multimedia, retrieval, etc. Automatic environmental sound classification is a growing area of research with numerous real-world applications. There are many research fields related to audio such as speech, applications of AI in social media and so on, but the work on the classification of environmental sounds is relatively scarce.</li> 
<li>In this project, different urban sounds have been classified using deep learning algorithms. A Convolutional Neural Network (CNN) model is trained using in-built python libraries such as NumPy, pandas, librosa and keras. The trained model is used to predict different urban sounds that occur in the environment. </li>
</ul>

<h2>Design of the system</h2>
<ul>
<li>CNNs are a class of multi-layer neural networks which contain convolution layers, subsampling layers and fully connected layers. While the network complexity is high due to the large amount of connectivity, the use of shared weights within layers assists in reducing the number of parameters that need to be trained.</li><li> The dataset used for this project is UrbanSound8K, taken from Kaggle.</li><li> The audio clips of urban sounds that occur in the environment, are converted to pictures, which are called spectrograms. Features from these spectrograms such as the MFCC (Mel-frequency cepstral coefficient) are extracted using librosa library and is used to train the model.</li><li>The NumPy and pandas libraries in python are used to manipulate the dataset in the form of arrays, which makes it easier when training the data, keras and TensorFlow are used to test and train the data, while matplotlib is used to show graphical representations of the results.</li><li>The dataset is split into “train” and “test” data and the test data is used to check the performance of the trained model after it has been trained using the deep learning algorithms and hence the results of how it predicts various urban sounds in the environment can be plotted as a graph, and finally we will be able to see the model’s prediction accuracy. 

Django has been used to provide a user interface for the user. On uploading the audio file from the system, the interface will display the audio file, its spectrogram graph, and the name of the audio that was uploaded to the system, with 90% accuracy. 
